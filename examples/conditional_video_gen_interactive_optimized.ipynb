{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "CBottle Video Conditional Animation\n",
        "====================================\n",
        "\n",
        "Create conditional weather forecast animations using CBottleVideo with ERA5 data.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.colors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from datetime import datetime, timedelta\n",
        "import cartopy.crs as ccrs\n",
        "\n",
        "from earth2studio.data import WB2ERA5\n",
        "from earth2studio.lexicon import WB2Lexicon, CBottleLexicon\n",
        "from earth2studio.models.dx import CBottleInfill\n",
        "from earth2studio.models.px import CBottleVideo\n",
        "from earth2studio.data.utils import fetch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Parameters - CONFIGURE THESE\n",
        "VIDEO_VARIABLE = \"t850\"\n",
        "N_FRAMES = 12  # 0-66 hours in 6-hour steps\n",
        "SEED = 42\n",
        "INTERPOLATE = True\n",
        "\n",
        "date_dict = {'year': 2022, 'month': 6, 'day': 1, 'hour': 0, 'minute': 0, 'second': 0}\n",
        "\n",
        "def generate_datetime_array(year, month, day, hour=0, minute=0, second=0):\n",
        "    \"\"\"\n",
        "    Generate a numpy array of 12 datetime objects spaced 6 hours apart.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    year : int\n",
        "        Year\n",
        "    month : int\n",
        "        Month (1-12)\n",
        "    day : int\n",
        "        Day of month\n",
        "    hour : int, optional\n",
        "        Hour (0-23), default 0\n",
        "    minute : int, optional\n",
        "        Minute (0-59), default 0\n",
        "    second : int, optional\n",
        "        Second (0-59), default 0\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    numpy.ndarray\n",
        "        Array of 12 datetime64[ns] objects spaced 6 hours apart\n",
        "    \"\"\"\n",
        "    # Create the starting datetime\n",
        "    start_time = datetime(year, month, day, hour, minute, second)\n",
        "    \n",
        "    # Generate 12 timestamps spaced 6 hours apart\n",
        "    times = [start_time + timedelta(hours=6*i) for i in range(12)]\n",
        "    \n",
        "    # Convert to numpy array with datetime64[ns] dtype\n",
        "    times_array = np.array(times, dtype=\"datetime64[ns]\")\n",
        "    \n",
        "    return times_array\n",
        "\n",
        "# Example usage:\n",
        "times = generate_datetime_array(date_dict['year'], date_dict['month'], date_dict['day'])\n",
        "print(times)\n",
        "print(f\"\\nShape: {times.shape}\")\n",
        "print(f\"Dtype: {times.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Step 1: Determine Available ERA5 Variables\n",
        "# ============================================================================\n",
        "print(\"\\nDetermining available ERA5 variables...\")\n",
        "wb2_vars = set(WB2Lexicon.VOCAB.keys())\n",
        "cbottle_vars = list(CBottleLexicon.VOCAB.keys())\n",
        "available_in_era5 = sorted([v for v in cbottle_vars if v in wb2_vars])\n",
        "\n",
        "print(f\"Using {len(available_in_era5)} ERA5 variables for conditioning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Step 2: Fetch and Infill ERA5 Data\n",
        "# ============================================================================\n",
        "print(\"\\nFetching ERA5 data...\")\n",
        "era5_ds = WB2ERA5()\n",
        "\n",
        "# Fetch ERA5 data ONCE\n",
        "era5_x, era5_coords = fetch_data(era5_ds, times, available_in_era5, device=device)\n",
        "print(f\"ERA5 data shape: {era5_x.shape}\")\n",
        "\n",
        "# Load and run CBottleInfill\n",
        "print(\"\\nRunning CBottleInfill...\")\n",
        "package_infill = CBottleInfill.load_default_package()\n",
        "cbottle_infill = CBottleInfill.load_model(\n",
        "    package_infill,\n",
        "    input_variables=available_in_era5,\n",
        "    sampler_steps=18\n",
        ")\n",
        "cbottle_infill = cbottle_infill.to(device)\n",
        "cbottle_infill.set_seed(SEED)\n",
        "\n",
        "# Run infilling\n",
        "infilled_x, infilled_coords = cbottle_infill(era5_x, era5_coords)\n",
        "print(f\"Infilled data shape: {infilled_x.shape}\")\n",
        "\n",
        "# CRITICAL: Free CBottleInfill and ERA5 data from GPU\n",
        "del cbottle_infill, era5_x, era5_coords\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"✓ Freed CBottleInfill from GPU memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Step 3: Prepare Conditional Input\n",
        "# ============================================================================\n",
        "print(\"\\nPreparing conditional input...\")\n",
        "\n",
        "# Add batch dimension if needed\n",
        "if len(infilled_x.shape) == 5:  # [time, lead_time, variable, lat, lon]\n",
        "    x_cond = infilled_x.unsqueeze(0)  # [batch, time, lead_time, variable, lat, lon]\n",
        "else:\n",
        "    x_cond = infilled_x\n",
        "\n",
        "print(f\"Conditional input shape: {x_cond.shape}\")\n",
        "\n",
        "# OPTIMIZED: Apply masking IN-PLACE (no clone needed)\n",
        "if INTERPOLATE:\n",
        "    print(\"Applying interpolation masking (in-place)...\")\n",
        "    x_cond[:, 1:-1, :, :, :, :] = float('nan')  # Mask middle timesteps\n",
        "    print(f\"Masked {x_cond.shape[1] - 2} middle frames for interpolation\")\n",
        "\n",
        "# CRITICAL: Free infilled data from GPU NOW (before loading CBottleVideo)\n",
        "del infilled_x, infilled_coords\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"✓ Freed infilled data from GPU memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Step 4: Run CBottleVideo Inference\n",
        "# ============================================================================\n",
        "print(\"\\nLoading CBottleVideo...\")\n",
        "package_video = CBottleVideo.load_default_package()\n",
        "cbottle_video = CBottleVideo.load_model(package_video, seed=SEED)\n",
        "cbottle_video = cbottle_video.to(device)\n",
        "\n",
        "# Setup coordinates\n",
        "coords_cond = cbottle_video.input_coords()\n",
        "coords_cond[\"time\"] = times\n",
        "coords_cond[\"batch\"] = np.array([0])\n",
        "coords_cond[\"variable\"] = cbottle_video.VARIABLES\n",
        "\n",
        "print(\"Running conditional video generation...\")\n",
        "print(f\"Input shape: {x_cond.shape}\")\n",
        "print(f\"Note: Masking triggers dual forward passes (conditional + unconditional)\")\n",
        "print(f\"      This uses ~2x memory per denoising step\\n\")\n",
        "\n",
        "iterator = cbottle_video.create_iterator(x_cond, coords_cond)\n",
        "\n",
        "# CRITICAL: Move x_cond to CPU immediately after iterator is created\n",
        "# The iterator may have captured what it needs already\n",
        "x_cond = x_cond.cpu()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"✓ Moved input data to CPU\\n\")\n",
        "\n",
        "# Collect outputs (moved to CPU immediately)\n",
        "outputs = []\n",
        "coords_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for step, (output, output_coords) in enumerate(iterator):\n",
        "    lead_time = output_coords[\"lead_time\"][0]\n",
        "    hours = int(lead_time / np.timedelta64(1, \"h\"))\n",
        "    print(f\"  Step {step}: +{hours}h\")\n",
        "\n",
        "    # CRITICAL: Move to CPU immediately\n",
        "    outputs.append(output.cpu())\n",
        "    coords_list.append(output_coords)\n",
        "\n",
        "    # Free GPU memory after each step\n",
        "    del output\n",
        "    if step % 3 == 0:  # Periodic cleanup\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if step >= N_FRAMES - 1:\n",
        "        break\n",
        "\n",
        "# CRITICAL: Free CBottleVideo from GPU\n",
        "del cbottle_video\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"\\n✓ Freed CBottleVideo from GPU memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Step 5: Create Animation\n",
        "# ============================================================================\n",
        "print(f\"\\nCreating animation for variable: {VIDEO_VARIABLE}\")\n",
        "\n",
        "# Find variable index\n",
        "var_names = coords_list[0][\"variable\"]\n",
        "try:\n",
        "    var_idx = np.where(var_names == VIDEO_VARIABLE)[0][0]\n",
        "except IndexError:\n",
        "    print(f\"Error: Variable '{VIDEO_VARIABLE}' not found!\")\n",
        "    print(f\"Available variables: {list(var_names)}\")\n",
        "    raise\n",
        "\n",
        "# Setup plot\n",
        "plt.style.use(\"dark_background\")\n",
        "projection = ccrs.Orthographic(central_longitude=0.0, central_latitude=45.0)\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection=projection)\n",
        "\n",
        "# Get data range for colormap\n",
        "data_min = min(outputs[i][0, 0, 0, var_idx].min() for i in range(len(outputs)))\n",
        "data_max = max(outputs[i][0, 0, 0, var_idx].max() for i in range(len(outputs)))\n",
        "norm = matplotlib.colors.Normalize(vmin=data_min, vmax=data_max)\n",
        "\n",
        "# First frame\n",
        "data_first = outputs[0][0, 0, 0, var_idx].numpy()\n",
        "img = ax.pcolormesh(\n",
        "    coords_list[0][\"lon\"],\n",
        "    coords_list[0][\"lat\"],\n",
        "    data_first,\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    cmap=\"viridis\",\n",
        "    norm=norm,\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.gridlines()\n",
        "plt.colorbar(\n",
        "    img, ax=ax, orientation=\"horizontal\", shrink=0.5, pad=0.05, label=f\"{VIDEO_VARIABLE}\"\n",
        ")\n",
        "\n",
        "# Initial title\n",
        "lead_time = coords_list[0][\"lead_time\"][0]\n",
        "hours = int(lead_time / np.timedelta64(1, \"h\"))\n",
        "time_str = pd.Timestamp(\n",
        "    coords_list[0][\"time\"][0] + coords_list[0][\"lead_time\"][0]\n",
        ").strftime(\"%Y-%m-%d %H:%M\")\n",
        "title = ax.set_title(\n",
        "    f\"Conditional Generation (ERA5): {VIDEO_VARIABLE} +{hours:03d}h ({time_str})\"\n",
        ")\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "\n",
        "def update_cond(frame):\n",
        "    \"\"\"Update conditional animation frame\"\"\"\n",
        "    data = outputs[frame][0, 0, 0, var_idx].numpy()\n",
        "    img.set_array(data.ravel())\n",
        "\n",
        "    lead_time = coords_list[frame][\"lead_time\"][0]\n",
        "    hours = int(lead_time / np.timedelta64(1, \"h\"))\n",
        "    time_str = pd.Timestamp(\n",
        "        coords_list[frame][\"time\"][0] + coords_list[frame][\"lead_time\"][0]\n",
        "    ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    title.set_text(\n",
        "        f\"Conditional Generation (ERA5): {VIDEO_VARIABLE} +{hours:03d}h ({time_str})\"\n",
        "    )\n",
        "    return [img, title]\n",
        "\n",
        "\n",
        "# Create animation\n",
        "print(\"Creating conditional video...\")\n",
        "anim_cond = animation.FuncAnimation(\n",
        "    fig, update_cond, frames=len(outputs), interval=500, blit=True\n",
        ")\n",
        "\n",
        "# Save video\n",
        "writer = animation.FFMpegWriter(fps=2)\n",
        "output_file = f\"outputs/conditional_video_{VIDEO_VARIABLE}_optimized.mp4\"\n",
        "anim_cond.save(output_file, writer=writer, dpi=100)\n",
        "plt.close()\n",
        "print(f\"✓ Conditional video saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Memory Optimization Summary\n",
        "\n",
        "**Key optimizations applied:**\n",
        "\n",
        "1. **In-place masking (Cell 5):**\n",
        "   - Original: `x_cond_masked = x_cond.clone()` (creates full GPU copy)\n",
        "   - Optimized: `x_cond[:, 1:-1, :, :, :, :] = float('nan')` (in-place modification)\n",
        "   - Savings: ~6 GB GPU memory\n",
        "\n",
        "2. **Early cleanup (Cell 5):**\n",
        "   - Free `infilled_x` and `infilled_coords` BEFORE loading CBottleVideo\n",
        "   - Ensures maximum free memory when loading the video model\n",
        "\n",
        "3. **Immediate CPU transfer (Cell 6):**\n",
        "   - Move `x_cond` to CPU right after iterator creation\n",
        "   - Frees ~6 GB of GPU memory during inference\n",
        "\n",
        "4. **Understanding masking overhead:**\n",
        "   - NaN masking triggers dual forward passes (conditional + unconditional)\n",
        "   - This uses ~2x memory per denoising step\n",
        "   - Necessary for frame interpolation, but important to be aware of\n",
        "\n",
        "**Total memory savings: ~12+ GB GPU memory**\n",
        "\n",
        "This should allow frame interpolation to complete successfully on your 44GB GPU."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
