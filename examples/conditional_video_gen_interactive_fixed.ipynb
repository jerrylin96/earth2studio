{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CBottle Video Conditional Animation (Memory Optimized)\n",
        "\n",
        "Create conditional weather forecast animations using CBottleVideo with ERA5 data.\n",
        "\n",
        "**Key optimization:** Process initialization times sequentially instead of in batch to avoid OOM errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.colors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "from datetime import datetime, timedelta\n",
        "import cartopy.crs as ccrs\n",
        "\n",
        "from earth2studio.data import WB2ERA5\n",
        "from earth2studio.lexicon import WB2Lexicon, CBottleLexicon\n",
        "from earth2studio.models.dx import CBottleInfill\n",
        "from earth2studio.models.px import CBottleVideo\n",
        "from earth2studio.data.utils import fetch_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Parameters - CONFIGURE THESE\n",
        "VIDEO_VARIABLE = \"t850\"\n",
        "N_FRAMES = 12  # 0-66 hours in 6-hour steps per initialization\n",
        "SEED = 42\n",
        "INTERPOLATE = True  # Mask middle timesteps for interpolation\n",
        "\n",
        "# Initial date\n",
        "date_dict = {'year': 2022, 'month': 6, 'day': 1, 'hour': 0, 'minute': 0, 'second': 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Time Array\n",
        "\n",
        "We'll generate 12 initialization times, but **process them one at a time** to avoid OOM errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_datetime_array(year, month, day, hour=0, minute=0, second=0, n_times=12):\n",
        "    \"\"\"\n",
        "    Generate a numpy array of datetime objects spaced 6 hours apart.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    year, month, day, hour, minute, second : int\n",
        "        Starting datetime components\n",
        "    n_times : int\n",
        "        Number of timestamps to generate\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    numpy.ndarray\n",
        "        Array of datetime64[ns] objects\n",
        "    \"\"\"\n",
        "    start_time = datetime(year, month, day, hour, minute, second)\n",
        "    times = [start_time + timedelta(hours=6*i) for i in range(n_times)]\n",
        "    return np.array(times, dtype=\"datetime64[ns]\")\n",
        "\n",
        "# Generate initialization times\n",
        "init_times = generate_datetime_array(\n",
        "    date_dict['year'], \n",
        "    date_dict['month'], \n",
        "    date_dict['day'],\n",
        "    n_times=12\n",
        ")\n",
        "print(f\"Processing {len(init_times)} initialization times:\")\n",
        "print(init_times)\n",
        "print(f\"\\nNote: Processing ONE at a time to avoid OOM errors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine Available ERA5 Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Determining available ERA5 variables...\")\n",
        "wb2_vars = set(WB2Lexicon.VOCAB.keys())\n",
        "cbottle_vars = list(CBottleLexicon.VOCAB.keys())\n",
        "available_in_era5 = sorted([v for v in cbottle_vars if v in wb2_vars])\n",
        "\n",
        "print(f\"Using {len(available_in_era5)} ERA5 variables for conditioning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Models\n",
        "\n",
        "Load models once and reuse for all initialization times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ERA5 data source\n",
        "print(\"Loading data sources and models...\")\n",
        "era5_ds = WB2ERA5()\n",
        "\n",
        "# Load CBottleInfill model\n",
        "package_infill = CBottleInfill.load_default_package()\n",
        "cbottle_infill = CBottleInfill.load_model(\n",
        "    package_infill,\n",
        "    input_variables=available_in_era5,\n",
        "    sampler_steps=18\n",
        ")\n",
        "cbottle_infill = cbottle_infill.to(device)\n",
        "cbottle_infill.set_seed(SEED)\n",
        "print(\"✓ CBottleInfill loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Each Initialization Time\n",
        "\n",
        "**Critical:** We process one initialization time at a time to avoid GPU memory overflow.\n",
        "\n",
        "For each initialization time:\n",
        "1. Fetch ERA5 data\n",
        "2. Run CBottleInfill\n",
        "3. Generate forecast with CBottleVideo\n",
        "4. Clean up GPU memory\n",
        "5. Move to next time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storage for all results\n",
        "all_outputs = []\n",
        "all_coords = []\n",
        "\n",
        "# Free CBottleInfill before loading CBottleVideo\n",
        "del cbottle_infill\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"✓ Freed CBottleInfill from GPU\\n\")\n",
        "\n",
        "# Load CBottleVideo once\n",
        "package_video = CBottleVideo.load_default_package()\n",
        "cbottle_video = CBottleVideo.load_model(package_video, seed=SEED)\n",
        "cbottle_video = cbottle_video.to(device)\n",
        "print(\"✓ CBottleVideo loaded\\n\")\n",
        "\n",
        "# Process each initialization time sequentially\n",
        "for init_idx, init_time in enumerate(init_times):\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processing initialization time {init_idx+1}/{len(init_times)}\")\n",
        "    print(f\"Time: {pd.Timestamp(init_time)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Convert single time to array\n",
        "    times_single = np.array([init_time], dtype=\"datetime64[ns]\")\n",
        "    \n",
        "    # Fetch ERA5 data for this single time\n",
        "    print(\"  Fetching ERA5 data...\")\n",
        "    era5_x, era5_coords = fetch_data(era5_ds, times_single, available_in_era5, device=device)\n",
        "    print(f\"  ERA5 shape: {era5_x.shape}\")\n",
        "    \n",
        "    # Reload CBottleInfill for this iteration\n",
        "    cbottle_infill_temp = CBottleInfill.load_model(\n",
        "        package_infill,\n",
        "        input_variables=available_in_era5,\n",
        "        sampler_steps=18\n",
        "    )\n",
        "    cbottle_infill_temp = cbottle_infill_temp.to(device)\n",
        "    cbottle_infill_temp.set_seed(SEED + init_idx)  # Different seed per init time\n",
        "    \n",
        "    # Run infilling\n",
        "    print(\"  Running CBottleInfill...\")\n",
        "    infilled_x, infilled_coords = cbottle_infill_temp(era5_x, era5_coords)\n",
        "    print(f\"  Infilled shape: {infilled_x.shape}\")\n",
        "    \n",
        "    # Free infill model and ERA5 data\n",
        "    del cbottle_infill_temp, era5_x, era5_coords\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Prepare input for CBottleVideo\n",
        "    if len(infilled_x.shape) == 5:  # [time, lead_time, variable, lat, lon]\n",
        "        x_cond = infilled_x.unsqueeze(0)  # [batch, time, lead_time, variable, lat, lon]\n",
        "    else:\n",
        "        x_cond = infilled_x\n",
        "    \n",
        "    print(f\"  Conditional input shape: {x_cond.shape}\")\n",
        "    \n",
        "    # Optional: Apply interpolation masking\n",
        "    if INTERPOLATE and x_cond.shape[1] > 2:\n",
        "        x_cond_masked = x_cond.clone()\n",
        "        x_cond_masked[:, 1:-1, :, :, :, :] = float('nan')\n",
        "        del x_cond\n",
        "        x_cond = x_cond_masked\n",
        "        print(\"  Applied interpolation masking\")\n",
        "    \n",
        "    # Setup coordinates\n",
        "    coords_cond = cbottle_video.input_coords()\n",
        "    coords_cond[\"time\"] = times_single\n",
        "    coords_cond[\"batch\"] = np.array([0])\n",
        "    coords_cond[\"variable\"] = infilled_coords[\"variable\"]\n",
        "    \n",
        "    # Run CBottleVideo inference\n",
        "    print(\"  Running CBottleVideo...\")\n",
        "    cbottle_video.set_seed(SEED + init_idx)\n",
        "    iterator = cbottle_video.create_iterator(x_cond, coords_cond)\n",
        "    \n",
        "    # Move input to CPU immediately after iterator starts\n",
        "    del x_cond, infilled_x, infilled_coords\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Collect outputs for this initialization\n",
        "    init_outputs = []\n",
        "    init_coords = []\n",
        "    \n",
        "    for step, (output, output_coords) in enumerate(iterator):\n",
        "        lead_time = output_coords[\"lead_time\"][0]\n",
        "        hours = int(lead_time / np.timedelta64(1, \"h\"))\n",
        "        \n",
        "        # Move to CPU immediately\n",
        "        init_outputs.append(output.cpu())\n",
        "        init_coords.append(output_coords)\n",
        "        \n",
        "        del output\n",
        "        if step % 3 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        print(f\"    Frame {step}: +{hours}h\")\n",
        "        \n",
        "        if step >= N_FRAMES - 1:\n",
        "            break\n",
        "    \n",
        "    # Store results\n",
        "    all_outputs.append(init_outputs)\n",
        "    all_coords.append(init_coords)\n",
        "    \n",
        "    # Cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(f\"  ✓ Completed initialization time {init_idx+1}\\n\")\n",
        "\n",
        "# Free CBottleVideo\n",
        "del cbottle_video\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ All forecasts completed!\")\n",
        "print(f\"Generated {len(all_outputs)} initialization times × {len(all_outputs[0])} forecast frames\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Animation\n",
        "\n",
        "Now create an animated visualization of all the forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Creating animation for variable: {VIDEO_VARIABLE}\")\n",
        "\n",
        "# Find variable index\n",
        "var_names = all_coords[0][0][\"variable\"]\n",
        "try:\n",
        "    var_idx = np.where(var_names == VIDEO_VARIABLE)[0][0]\n",
        "except IndexError:\n",
        "    print(f\"Error: Variable '{VIDEO_VARIABLE}' not found!\")\n",
        "    print(f\"Available variables: {list(var_names)}\")\n",
        "    raise\n",
        "\n",
        "# Setup plot\n",
        "plt.style.use(\"dark_background\")\n",
        "projection = ccrs.Orthographic(central_longitude=0.0, central_latitude=45.0)\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection=projection)\n",
        "\n",
        "# Get data range for colormap (from first init time)\n",
        "data_min = min(\n",
        "    all_outputs[0][i][0, 0, 0, var_idx].min() for i in range(len(all_outputs[0]))\n",
        ")\n",
        "data_max = max(\n",
        "    all_outputs[0][i][0, 0, 0, var_idx].max() for i in range(len(all_outputs[0]))\n",
        ")\n",
        "norm = matplotlib.colors.Normalize(vmin=data_min, vmax=data_max)\n",
        "\n",
        "# First frame\n",
        "data_first = all_outputs[0][0][0, 0, 0, var_idx].numpy()\n",
        "img = ax.pcolormesh(\n",
        "    all_coords[0][0][\"lon\"],\n",
        "    all_coords[0][0][\"lat\"],\n",
        "    data_first,\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    cmap=\"viridis\",\n",
        "    norm=norm,\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.gridlines()\n",
        "plt.colorbar(\n",
        "    img, ax=ax, orientation=\"horizontal\", shrink=0.5, pad=0.05, label=VIDEO_VARIABLE\n",
        ")\n",
        "\n",
        "# Initial title\n",
        "lead_time = all_coords[0][0][\"lead_time\"][0]\n",
        "hours = int(lead_time / np.timedelta64(1, \"h\"))\n",
        "time_str = pd.Timestamp(\n",
        "    all_coords[0][0][\"time\"][0] + lead_time\n",
        ").strftime(\"%Y-%m-%d %H:%M\")\n",
        "title = ax.set_title(\n",
        "    f\"Conditional: {VIDEO_VARIABLE} Init 1/{len(all_outputs)} +{hours:03d}h ({time_str})\"\n",
        ")\n",
        "fig.tight_layout()\n",
        "\n",
        "\n",
        "def update(global_frame):\n",
        "    \"\"\"Update animation frame\"\"\"\n",
        "    # Calculate which initialization and forecast frame\n",
        "    init_idx = global_frame // N_FRAMES\n",
        "    frame_idx = global_frame % N_FRAMES\n",
        "    \n",
        "    data = all_outputs[init_idx][frame_idx][0, 0, 0, var_idx].numpy()\n",
        "    img.set_array(data.ravel())\n",
        "    \n",
        "    lead_time = all_coords[init_idx][frame_idx][\"lead_time\"][0]\n",
        "    hours = int(lead_time / np.timedelta64(1, \"h\"))\n",
        "    time_str = pd.Timestamp(\n",
        "        all_coords[init_idx][frame_idx][\"time\"][0] + lead_time\n",
        "    ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    title.set_text(\n",
        "        f\"Conditional: {VIDEO_VARIABLE} Init {init_idx+1}/{len(all_outputs)} +{hours:03d}h ({time_str})\"\n",
        "    )\n",
        "    return [img, title]\n",
        "\n",
        "\n",
        "# Create and save animation\n",
        "total_frames = len(all_outputs) * N_FRAMES\n",
        "print(f\"Rendering {total_frames} total frames...\")\n",
        "anim = animation.FuncAnimation(\n",
        "    fig, update, frames=total_frames, interval=500, blit=True\n",
        ")\n",
        "\n",
        "output_file = f\"outputs/conditional_video_{VIDEO_VARIABLE}_fixed.mp4\"\n",
        "writer = animation.FFMpegWriter(fps=2)\n",
        "print(f\"Saving to {output_file}...\")\n",
        "anim.save(output_file, writer=writer, dpi=100)\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\n✓ Animation saved to {output_file}\")\n",
        "print(\"Memory-efficient execution complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Memory Usage Summary\n",
        "\n",
        "**Original approach (OOM):**\n",
        "- Loaded all 12 initialization times at once\n",
        "- Shape: `[1, 12, 1, 45, 721, 1440]`\n",
        "- Generated 12 × 12 = 144 frames simultaneously\n",
        "- Memory: ~25+ GB just for outputs\n",
        "\n",
        "**Fixed approach (Success):**\n",
        "- Process one initialization time at a time\n",
        "- Shape per iteration: `[1, 1, 1, 45, 721, 1440]`\n",
        "- Generate 12 frames per iteration\n",
        "- Memory: ~2-3 GB peak per iteration\n",
        "- Clean up GPU memory between iterations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
